{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "Saving vectors of label - 'bed': 100%|██████████| 1713/1713 [00:19<00:00, 87.24it/s] \n",
      "Saving vectors of label - 'happy': 100%|██████████| 1742/1742 [00:19<00:00, 89.08it/s] \n",
      "Saving vectors of label - 'cat': 100%|██████████| 1733/1733 [00:19<00:00, 89.63it/s] \n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from preprocess import *\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Second dimension of the feature is dim2\n",
    "feature_dim_2 = 11\n",
    "\n",
    "# Save data to array file first\n",
    "save_data_to_array(max_len=feature_dim_2)\n",
    "\n",
    "# # Loading train set and test set\n",
    "X_train, X_test, y_train, y_test = get_train_test()\n",
    "\n",
    "# # Feature dimension\n",
    "feature_dim_1 = 20\n",
    "channel = 1\n",
    "epochs = 50\n",
    "batch_size = 100\n",
    "verbose = 1\n",
    "num_classes = 3\n",
    "\n",
    "# Reshaping to perform 2D convolution\n",
    "X_train = X_train.reshape(X_train.shape[0], feature_dim_1, feature_dim_2, channel)\n",
    "X_test = X_test.reshape(X_test.shape[0], feature_dim_1, feature_dim_2, channel)\n",
    "\n",
    "y_train_hot = to_categorical(y_train)\n",
    "y_test_hot = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(2, 2), activation='relu', input_shape=(feature_dim_1, feature_dim_2, channel)))\n",
    "    model.add(Conv2D(48, kernel_size=(2, 2), activation='relu'))\n",
    "    model.add(Conv2D(120, kernel_size=(2, 2), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Predicts one sample\n",
    "def predict(filepath, model):\n",
    "    sample = wav2mfcc(filepath)\n",
    "    sample_reshaped = sample.reshape(1, feature_dim_1, feature_dim_2, channel)\n",
    "    return get_labels()[0][\n",
    "            np.argmax(model.predict(sample_reshaped))\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building The Model Then Training it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3112 samples, validate on 2076 samples\n",
      "Epoch 1/50\n",
      "3112/3112 [==============================] - 5s 2ms/step - loss: 1.6072 - acc: 0.4566 - val_loss: 0.8331 - val_acc: 0.5891\n",
      "Epoch 2/50\n",
      "3112/3112 [==============================] - 2s 623us/step - loss: 0.7199 - acc: 0.6880 - val_loss: 0.5555 - val_acc: 0.7905\n",
      "Epoch 3/50\n",
      "3112/3112 [==============================] - 2s 635us/step - loss: 0.5228 - acc: 0.8004 - val_loss: 0.3931 - val_acc: 0.8593\n",
      "Epoch 4/50\n",
      "3112/3112 [==============================] - 2s 655us/step - loss: 0.4391 - acc: 0.8470 - val_loss: 0.4156 - val_acc: 0.8545\n",
      "Epoch 5/50\n",
      "3112/3112 [==============================] - 2s 644us/step - loss: 0.3468 - acc: 0.8756 - val_loss: 0.3119 - val_acc: 0.8820\n",
      "Epoch 6/50\n",
      "3112/3112 [==============================] - 2s 641us/step - loss: 0.2936 - acc: 0.8952 - val_loss: 0.2480 - val_acc: 0.9090\n",
      "Epoch 7/50\n",
      "3112/3112 [==============================] - 2s 640us/step - loss: 0.2423 - acc: 0.9161 - val_loss: 0.2745 - val_acc: 0.8960\n",
      "Epoch 8/50\n",
      "3112/3112 [==============================] - 2s 648us/step - loss: 0.2180 - acc: 0.9235 - val_loss: 0.2029 - val_acc: 0.9215\n",
      "Epoch 9/50\n",
      "3112/3112 [==============================] - 2s 773us/step - loss: 0.2144 - acc: 0.9319 - val_loss: 0.4293 - val_acc: 0.8685\n",
      "Epoch 10/50\n",
      "3112/3112 [==============================] - 2s 658us/step - loss: 0.1563 - acc: 0.9479 - val_loss: 0.1731 - val_acc: 0.9350\n",
      "Epoch 11/50\n",
      "3112/3112 [==============================] - 2s 655us/step - loss: 0.1239 - acc: 0.9569 - val_loss: 0.2191 - val_acc: 0.9253\n",
      "Epoch 12/50\n",
      "3112/3112 [==============================] - 2s 654us/step - loss: 0.1027 - acc: 0.9679 - val_loss: 0.1659 - val_acc: 0.9441\n",
      "Epoch 13/50\n",
      "3112/3112 [==============================] - 2s 732us/step - loss: 0.0984 - acc: 0.9666 - val_loss: 0.1595 - val_acc: 0.9417\n",
      "Epoch 14/50\n",
      "3112/3112 [==============================] - 2s 665us/step - loss: 0.0673 - acc: 0.9765 - val_loss: 0.2245 - val_acc: 0.9273\n",
      "Epoch 15/50\n",
      "3112/3112 [==============================] - 2s 658us/step - loss: 0.0758 - acc: 0.9720 - val_loss: 0.1875 - val_acc: 0.9456\n",
      "Epoch 16/50\n",
      "3112/3112 [==============================] - 2s 780us/step - loss: 0.0616 - acc: 0.9801 - val_loss: 0.1951 - val_acc: 0.9408\n",
      "Epoch 17/50\n",
      "3112/3112 [==============================] - 2s 666us/step - loss: 0.0564 - acc: 0.9785 - val_loss: 0.1848 - val_acc: 0.9417\n",
      "Epoch 18/50\n",
      "3112/3112 [==============================] - 2s 669us/step - loss: 0.0397 - acc: 0.9855 - val_loss: 0.1960 - val_acc: 0.9465\n",
      "Epoch 19/50\n",
      "3112/3112 [==============================] - 2s 683us/step - loss: 0.0415 - acc: 0.9852 - val_loss: 0.1797 - val_acc: 0.9513\n",
      "Epoch 20/50\n",
      "3112/3112 [==============================] - 2s 756us/step - loss: 0.0460 - acc: 0.9865 - val_loss: 0.2402 - val_acc: 0.9465\n",
      "Epoch 21/50\n",
      "3112/3112 [==============================] - 2s 795us/step - loss: 0.0464 - acc: 0.9852 - val_loss: 0.1957 - val_acc: 0.9432\n",
      "Epoch 22/50\n",
      "3112/3112 [==============================] - 3s 845us/step - loss: 0.0290 - acc: 0.9916 - val_loss: 0.2083 - val_acc: 0.9436\n",
      "Epoch 23/50\n",
      "3112/3112 [==============================] - 2s 731us/step - loss: 0.0359 - acc: 0.9881 - val_loss: 0.3006 - val_acc: 0.9258\n",
      "Epoch 24/50\n",
      "3112/3112 [==============================] - 2s 670us/step - loss: 0.0479 - acc: 0.9888 - val_loss: 0.1864 - val_acc: 0.9504\n",
      "Epoch 25/50\n",
      "3112/3112 [==============================] - 2s 591us/step - loss: 0.0184 - acc: 0.9936 - val_loss: 0.2089 - val_acc: 0.9494\n",
      "Epoch 26/50\n",
      "3112/3112 [==============================] - 2s 527us/step - loss: 0.0241 - acc: 0.9929 - val_loss: 0.2078 - val_acc: 0.9562\n",
      "Epoch 27/50\n",
      "3112/3112 [==============================] - 2s 577us/step - loss: 0.0170 - acc: 0.9949 - val_loss: 0.2213 - val_acc: 0.9513\n",
      "Epoch 28/50\n",
      "3112/3112 [==============================] - 2s 534us/step - loss: 0.0201 - acc: 0.9923 - val_loss: 0.1953 - val_acc: 0.9475\n",
      "Epoch 29/50\n",
      "3112/3112 [==============================] - 2s 553us/step - loss: 0.0114 - acc: 0.9958 - val_loss: 0.2979 - val_acc: 0.9441\n",
      "Epoch 30/50\n",
      "3112/3112 [==============================] - 2s 534us/step - loss: 0.0172 - acc: 0.9949 - val_loss: 0.2088 - val_acc: 0.9576\n",
      "Epoch 31/50\n",
      "3112/3112 [==============================] - 2s 558us/step - loss: 0.0107 - acc: 0.9955 - val_loss: 0.7386 - val_acc: 0.9013\n",
      "Epoch 32/50\n",
      "3112/3112 [==============================] - 2s 687us/step - loss: 0.0277 - acc: 0.9910 - val_loss: 0.2183 - val_acc: 0.9518\n",
      "Epoch 33/50\n",
      "3112/3112 [==============================] - 2s 556us/step - loss: 0.0062 - acc: 0.9984 - val_loss: 0.2328 - val_acc: 0.9542\n",
      "Epoch 34/50\n",
      "3112/3112 [==============================] - 2s 575us/step - loss: 0.0153 - acc: 0.9958 - val_loss: 0.3164 - val_acc: 0.9316\n",
      "Epoch 35/50\n",
      "3112/3112 [==============================] - 2s 614us/step - loss: 0.0103 - acc: 0.9965 - val_loss: 0.2313 - val_acc: 0.9552\n",
      "Epoch 36/50\n",
      "3112/3112 [==============================] - 2s 716us/step - loss: 0.0182 - acc: 0.9949 - val_loss: 0.2352 - val_acc: 0.9523\n",
      "Epoch 37/50\n",
      "3112/3112 [==============================] - 2s 705us/step - loss: 0.0071 - acc: 0.9981 - val_loss: 0.2433 - val_acc: 0.9552\n",
      "Epoch 38/50\n",
      "3112/3112 [==============================] - 2s 733us/step - loss: 0.0067 - acc: 0.9978 - val_loss: 0.3083 - val_acc: 0.9480\n",
      "Epoch 39/50\n",
      "3112/3112 [==============================] - 2s 697us/step - loss: 0.0061 - acc: 0.9981 - val_loss: 0.2534 - val_acc: 0.9533\n",
      "Epoch 40/50\n",
      "3112/3112 [==============================] - 3s 815us/step - loss: 0.0157 - acc: 0.9965 - val_loss: 0.2363 - val_acc: 0.9542\n",
      "Epoch 41/50\n",
      "3112/3112 [==============================] - 2s 701us/step - loss: 0.0054 - acc: 0.9984 - val_loss: 0.2566 - val_acc: 0.9576\n",
      "Epoch 42/50\n",
      "3112/3112 [==============================] - 2s 780us/step - loss: 0.0177 - acc: 0.9942 - val_loss: 0.2677 - val_acc: 0.9504\n",
      "Epoch 43/50\n",
      "3112/3112 [==============================] - 2s 716us/step - loss: 0.0199 - acc: 0.9961 - val_loss: 0.2837 - val_acc: 0.9533\n",
      "Epoch 44/50\n",
      "3112/3112 [==============================] - 2s 693us/step - loss: 0.0048 - acc: 0.9984 - val_loss: 0.2554 - val_acc: 0.9480\n",
      "Epoch 45/50\n",
      "3112/3112 [==============================] - 2s 697us/step - loss: 0.0085 - acc: 0.9961 - val_loss: 0.2425 - val_acc: 0.9581\n",
      "Epoch 46/50\n",
      "3112/3112 [==============================] - 2s 696us/step - loss: 0.0114 - acc: 0.9984 - val_loss: 0.2558 - val_acc: 0.9538\n",
      "Epoch 47/50\n",
      "3112/3112 [==============================] - 2s 799us/step - loss: 0.0099 - acc: 0.9965 - val_loss: 0.2633 - val_acc: 0.9528\n",
      "Epoch 48/50\n",
      "3112/3112 [==============================] - 2s 696us/step - loss: 0.0078 - acc: 0.9978 - val_loss: 0.3102 - val_acc: 0.9571\n",
      "Epoch 49/50\n",
      "3112/3112 [==============================] - 2s 700us/step - loss: 0.0094 - acc: 0.9971 - val_loss: 0.3092 - val_acc: 0.9398\n",
      "Epoch 50/50\n",
      "3112/3112 [==============================] - 2s 699us/step - loss: 0.0099 - acc: 0.9971 - val_loss: 0.2814 - val_acc: 0.9547\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff5f82735f8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model()\n",
    "model.fit(X_train, y_train_hot, batch_size=batch_size, epochs=epochs, verbose=verbose, validation_data=(X_test, y_test_hot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n"
     ]
    }
   ],
   "source": [
    "print(predict('./0fa1e7a9_nohash_0.wav', model=model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
